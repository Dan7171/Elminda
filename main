from pathlib import Path
from time import strftime
import sklearn
from sklearn.linear_model import LinearRegression, KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from math import sqrt
import pandas as pd
import numpy as np
import datetime as dt
import warnings


warnings.simplefilter("ignore", UserWarning)
#import the_module_that_warns


def reformat_dates(df): 
    df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)
    df['just_date'] = pd.to_datetime(df['date']).dt.date
    newdate = dt.date(1998, 11, 8)
    df['just_date'].replace({pd.NaT: newdate}, inplace=True)
    df['just_date'] = df['just_date'].apply(lambda d: d.strftime("%d/%m/%Y"))
    addcol = df.pop('just_date')
    df.insert(2, 'just_date', addcol)
 
#for a subject with more than one EEG recording in the same day, keep only the first one
def unite_same_day_visits_to_the_first(df):
    df = df.sort_values(by=['subject','date'])
    df = df.reset_index()
    df = df.drop_duplicates(subset=['subject', 'just_date'], keep='first') #removes rows(visits) who has same subject with the same date, but leaves the first appearance
    df = df.reset_index()


def final_date(df1, df2): 
    #create final_date column for each df to be used in the merge of the two 
    #use a random t until Ofir gives us an answer
    t = 2 #t is the valid maximun difference in days
    df = df1.merge(df2, how = 'inner',on = ['subject'])
    df['final_date'] =[d1 if time_difference(d1,d2)<= t else "remove" for d1,d2 in zip(df['just_date_x'],df['just_date_y'])] 
    df = df[df['final_date']!= 'remove']
    df = df.reset_index()
    df = df.drop_duplicates(subset=['final_date','subject'], keep='first')
    df = df.reset_index()
     
 
def time_difference(d1_str, d2_str): #v
    d1 = dt.datetime.strptime(d1_str, "%d/%m/%Y")
    d2 = dt.datetime.strptime(d2_str, "%d/%m/%Y")
    delta = d2-d1
    difference = abs(delta.days)
    return difference   

def save_df_to_csv(df):
    path = Path()
    df.to_csv('visits.csv',index = False)

#*** MAIN PART : ***

bna = pd.read_csv('BNA_data.csv')
clinical = pd.read_csv("Clinical_data.csv") #Hebrew is reversed in the dataframe
print(clinical.columns)
reformat_dates(bna)
reformat_dates(clinical)
unite_same_day_visits_to_the_first(bna) # for every subject, leaves in df just the first visit on a given day
final_date(bna, clinical) 
visits = clinical.merge(bna, how = 'inner', on = ['just_date', 'subject']) 
save_df_to_csv(visits)

#
# do for all models:
#

# features:
# X = visits['age?', 'gender?', baseline feature 1, baseline feture 2...]]


#
# do for linear regression:
# 

## HDRS_drop ('response to treatment')= {100 - (HDRS week 6/ HDRS week 1) * 100}  - represetns the number of % the HDRS score lost in 6 weeks.
# in particular, HDRS_drop < 0 means HDRS score is greater in week 6 than it was in week 1 (more depression)     
# y = visits['HDRS_drop']

# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)
#lr = LinearRegreassion() 
#lr.fit(X_train, y_train)
#pred = lr.predict(X_test)



#
# do for classification:
#

# y = visits['HDRS_drop_level'] # level is one of 3 labels: ,'respone','non-response',and 'remission'
# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)
#knn = KNeighborsRegressor(n_neighbors=3) 3 for response, non- response and remission
#knn.fit(X_train, y_train)
#pred = knn.predict(X_test)
#mae = mean_absolute_error(y_test, pred) , to compute the mean absolute error (optional)


#BIOMARKERS:
#* Asymmetry alpha power (pair_mean_power_abs) fronal lobe
#* Asymmetry beta power (pair_mean_power_abs) central lobe
#* ...